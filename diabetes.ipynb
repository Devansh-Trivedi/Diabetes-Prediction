{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'https://raw.githubusercontent.com/Devansh-Trivedi/Diabetes-Prediction/main/diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "dataset.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.countplot(x = 'Outcome',data = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "seaborn.heatmap(dataset.corr(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the above visualizations we can observe\n",
    "1. the data is imbalanced\n",
    "2. the number of patients who have diabetes are less than that of who don't have.\n",
    "3. we can also see that Outcome and [Glucose,BMI,Age,Insulin] has high correlation.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing zero values with NaN\n",
    "dataset_new[[\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]] = dataset_new[[\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]].replace(0, np.NaN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of NaN\n",
    "dataset_new.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new[\"Glucose\"].fillna(dataset_new[\"Glucose\"].min(), inplace = True)\n",
    "dataset_new[\"BloodPressure\"].fillna(dataset_new[\"BloodPressure\"].min(), inplace = True)\n",
    "dataset_new[\"SkinThickness\"].fillna(dataset_new[\"SkinThickness\"].min(), inplace = True)\n",
    "dataset_new[\"Insulin\"].fillna(dataset_new[\"Insulin\"].min(), inplace = True)\n",
    "dataset_new[\"BMI\"].fillna(dataset_new[\"BMI\"].min(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling using MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "dataset_scaled = sc.fit_transform(dataset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_scaled = pd.DataFrame(dataset_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features - [Glucose, SkinThickness, Insulin, BMI, Age]\n",
    "X = dataset_scaled.iloc[:, [1, 3, 4, 5, 7]].values\n",
    "Y = dataset_scaled.iloc[:, 8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting X and Y\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 42, stratify = dataset_new['Outcome'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dimensions\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression = LogisticRegression(random_state = 42)\n",
    "logistic_regression.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a graph for n_neighbors \n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_axis = list(range(1, 31))\n",
    "acc = pd.Series()\n",
    "x = range(1,31)\n",
    "\n",
    "for i in list(range(1, 31)):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors = i) \n",
    "    knn_model.fit(X_train, Y_train)\n",
    "    prediction = knn_model.predict(X_test)\n",
    "    acc = acc.append(pd.Series(metrics.accuracy_score(prediction, Y_test)))\n",
    "plt.plot(X_axis, acc)\n",
    "plt.xticks(x)\n",
    "plt.title(\"Finding best value for n_estimators\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('Highest value: ',acc.values.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier Algorithm\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel = 'linear', random_state = 42)\n",
    "svc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Algorithm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree Algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 42)\n",
    "decision_tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest Algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators = 11, criterion = 'entropy', random_state = 42)\n",
    "random_forest.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on test dataset\n",
    "Y_pred_logistic_regression = logistic_regression.predict(X_test)\n",
    "Y_pred_svc = svc.predict(X_test)\n",
    "Y_pred_nb = nb.predict(X_test)\n",
    "Y_pred_decision_tree = decision_tree.predict(X_test)\n",
    "Y_pred_random_forest = random_forest.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating using accuracy_score metric\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_logistic_regression = accuracy_score(Y_test, Y_pred_logistic_regression)\n",
    "accuracy_svc = accuracy_score(Y_test, Y_pred_svc)\n",
    "accuracy_nb = accuracy_score(Y_test, Y_pred_nb)\n",
    "accuracy_decision_tree = accuracy_score(Y_test, Y_pred_decision_tree)\n",
    "accuracy_random_forest = accuracy_score(Y_test, Y_pred_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Accuracy on test set\n",
    "print(\"Logistic Regression: \" + str(accuracy_logistic_regression * 100))\n",
    "print(\"Support Vector Classifier: \" + str(accuracy_svc * 100))\n",
    "print(\"Naive Bayes: \" + str(accuracy_nb * 100))\n",
    "print(\"Decision tree: \" + str(accuracy_decision_tree * 100))\n",
    "print(\"Random Forest: \" + str(accuracy_random_forest * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred_random_forest)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of Confusion matrix\n",
    "seaborn.heatmap(pd.DataFrame(cm), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred_random_forest))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Model for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(random_forest, open('model.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
